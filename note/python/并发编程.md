#  并发编程

并发编程/多任务编程

多任务可以提高CPU的资源，提高程序的执行效率

多任务就是再同一时刻内执行多个任务 ， 相当于在电脑中同时运行着网易云 ， 微信 ， 浏览器……



并行 : 多个任务在同一时刻内一起执行（真正意义上的一起执行）

并发 ：在同一时刻内 ，资源有限的情况下 ， 多个任务相互交替的执行 



# 进程

进程是操作系统分配资源的基本单位 

进程操作系统的概念

- 把复杂的硬件操作封装
- 管理多个程序的执行
- 程序执行有两个情况（并发 ， 并行）

进程：就是正在运行的程序 。



### 创建进程

python自带提供了multiprocessing。该模块用来启动创建子进程 ， 该模块功能比较多 ， 可以创建子进程、通信和共享数据…… ， 提供了process、queue……

```
Process(target , args/kwargs)

# target :指定执行的任务名称
# args/kwargs : 参数

```

```
from  multiprocessing import Process
import time


def task():
    print('我是子进程')
    time.sleep(2)
    print('我在跳舞')
    time.sleep(1)
    print('子进程结束')

if __name__ == '__main__':
    print('我是父进程')
    s = time.time()
    # 创建好了子进程对象
    p = Process(target=task)
    # 启动子进程执行代码
    p.start()
    task()
    print(time.time() - s)
    print('父进程结束')
```

```
在创建进程的文件中要写上if __name__ == '__main__':
为了防止程序不断的递归创建子进程 ， 导致资源损耗
```

```
# 带参子进程
from  multiprocessing import Process
import time


def task(name):
    print('我是子进程')
    time.sleep(2)
    print(f'我是{name}在跳舞')
    time.sleep(1)
    print('子进程结束')

if __name__ == '__main__':
    print('我是父进程')
    # 创建好了子进程对象
    # p = Process(target=task , args=('哈巴罗',))
    p = Process(target=task , kwargs={'name':'哈巴罗'})
    # 启动子进程执行代码
    p.start()
```

进程之间的数据是相互隔离的 ， 子进程操作全局数据 ， 不会对父进程产生影响

```
from  multiprocessing import Process

age = 10

def task(name):
    global  age
    age = 0
    print('我是子进程')
    print(f'我是{name}在跳舞')
    print(f'{name}今年{age + 12}')
    print('子进程结束')

if __name__ == '__main__':
    print('我是父进程')
    # 创建好了子进程对象
    p = Process(target=task , args=('哈巴罗1号',))
    ac = Process(target=task , kwargs={'name':'哈巴罗2号'})
    # 启动子进程执行代码
    p.start()
    print(f'age是{age}')
```

```
os.getpid()  # 获取当前进程的编号
os.getppid()	# 在子进程中获取父进程编号
```

```
from multiprocessing import  Process
import os

def sing(name):
    # 获取当前进程的编号(子进程)
    print(f'子进程编号:{os.getpid()}')
    print(f'{name}在唱歌')
    # 获取父进程编号
    print(f'父进程编号为:{os.getppid()}')


if __name__ == '__main__':
    # 获取当前进程的编号（主/父进程）
    print(f'父进程编号:{os.getpid()}')
    # 创建子进程
    p = Process(target=sing , args=('美女',))
    p.start()
```

### 启动多进程

```
from multiprocessing import  Process

def song(num):
    print(f'这是我吃的第{num}碗面')


if __name__ == '__main__':
    print('主进程开始')
    for i in range(10):
        p = Process(target=song , args=(i,))
        p.start()
        p.join()    # 等到子进程结束之后在结束父进程
        '''
        这样写会出现一种阻塞情况 ，按照顺序启动执行进程 
        此时有些进程运行时间比较长 ， 需要进行等待 ， 就会出现阻塞情况
        '''
    print('主进程结束')
```

```
from multiprocessing import  Process

def song(num):
    print(f'这是我吃的第{num}碗面')


if __name__ == '__main__':
    print('主进程开始')
    p_list= [] # 把所有启动的进程添加到里面
    for i in range(10):
        p = Process(target=song , args=(i,))
        p.start()
        p_list.append(p)
        # p.join()    # 等到子进程结束之后在结束父进程
        '''
        这样写会出现一种阻塞情况 ，按照顺序启动执行进程 
        此时有些进程运行时间比较长 ， 需要进行等待 ， 就会出现阻塞情况
        '''
    for p in p_list:
        p.join()

    print('主进程结束')
```



```
from  multiprocessing import  Process
import time


def func():
    for i in range(5):
        print(f'在第{i}次干饭')
        time.sleep(1)


if __name__ == '__main__':

    p = Process(target=func)
    # 当主进程结束的时候 ， 也立刻结束掉子进程
    p.daemon = True
    p.start()
    time.sleep(2)
    print('结束')
```





# 线程

### 互斥锁

进程与进程之间的数据是不共享的 ， 可以使用文件共享数据实现进程之间通信。但共享会有竞争 ， 竞争带来的问题是错乱

```
from  multiprocessing import  Process
import time
import json


def search(name):
    time.sleep(1)
    dic = json.load(open('db.txt','r',encoding='utf-8'))
    print(f'{name}正在查看票源 ， 当前剩余票数为：{dic["count"]}')



def get(name):
    time.sleep(1)
    dic = json.load(open('db.txt', 'r', encoding='utf-8'))
    if dic["count"]>0:
        dic["count"]-=1
        time.sleep(2)
        json.dump(dic , open('db.txt', 'w', encoding='utf-8'))
        print(f'{name}购票成功')

def task(name):
    search(name)
    get(name)



if __name__ == '__main__':
    for i in range(1,5):
        p= Process(target=task,args=(f'Tom{i}号',))
        p.start()
```

互斥锁：就是多个进程同一个资源 ， 加上互斥锁就是把并发改成串行 ， 可以保证数据的安全不会错乱 ；但是效率比较低

加锁处理：保证数据安全，牺牲效率

```
from  multiprocessing import  Process , Lock
import time
import json


def search(name):
    time.sleep(1)
    dic = json.load(open('db.txt','r',encoding='utf-8'))
    print(f'{name}正在查看票源 ， 当前剩余票数为：{dic["count"]}')



def get(name):
    time.sleep(1)
    dic = json.load(open('db.txt', 'r', encoding='utf-8'))
    if dic["count"]>0:
        dic["count"]-=1
        time.sleep(2)
        json.dump(dic , open('db.txt', 'w', encoding='utf-8'))
        print(f'{name}购票成功')
    else:
        print(f'{name}购票失败')


def task(name,l):
    search(name)
    l.acquire()
    get(name)
    l.release()


if __name__ == '__main__':
    l = Lock()
    for i in range(1,5):
        p= Process(target=task,args=(f'Tom{i}号',l))
        p.start()
```

```
from  multiprocessing import  Process , Lock
import time
import json


def search(name):
    time.sleep(1)
    dic = json.load(open('db.txt','r',encoding='utf-8'))
    print(f'{name}正在查看票源 ， 当前剩余票数为：{dic["count"]}')



def get(name):
    time.sleep(1)
    dic = json.load(open('db.txt', 'r', encoding='utf-8'))
    if dic["count"]>0:
        dic["count"]-=1
        time.sleep(2)
        json.dump(dic , open('db.txt', 'w', encoding='utf-8'))
        print(f'{name}购票成功')
    else:
        print(f'{name}购票失败')


def task(name,l):
    search(name)
    l.acquire()
    get(name)
    l.release()


if __name__ == '__main__':
    l = Lock()
    for i in range(1,5):
        p= Process(target=task,args=(f'Tom{i}号',l))
        p.start()
        p.join()
```



### 信号量

信号量也是一把锁

互斥锁是同一时间是有一个任务能抢到锁

信号量同一时间有多个任务拿到锁去执行

```
from  multiprocessing import  Process , Semaphore
import time


def home(name,s):
    # 拿到锁
    s.acquire()
    print(f'{name}猥琐的进入小黑屋')
    time.sleep(3)
    print(f'{name}惊恐的跑出房间')
    # 归还锁
    s.release()


if __name__ == '__main__':
    # 设置信号量 ， 设置有多少锁
    s = Semaphore(3)
    for i in range(9):
        p = Process(target=home,args=(f'Tom{i}号',s))
        p.start()
```



### 线程

线程是资源分配单位 ，线程执行单位一个进程里面默认就会有一个线程的存在

```
from threading import Thread

def work(name):
    print(f'{name}在种田')


if __name__ == '__main__':

    t = Thread(target=work , args=('张三',))
    t.start()
```

```
from threading import Thread
from  multiprocessing import Process


def work(name):
    print(f'{name}在种田')
    global num
    num = 150
    print(num)


if __name__ == '__main__':
    # 线程
    # 在同一个进程当中 多个线程之间的数据是共享这个进程中的数据
    # num = 250
    # t = Thread(target=work , args=('张三',))
    # t.start()
    # t.join()
    # print(num)

    # 进程
    num = 250
    p = Process(target=work, args=('张三',))
    p.start()
    p.join()
    print(num)
```

创建进程类

```
from  multiprocessing import  Process
import  time


class MyProcess(Process):
    
    def __init__(self):
        super().__init__()

    def func(self):
        for i in range(5):
            print(f'在第{i}次干饭')
            time.sleep(1)

    def run(self):
        print('开始进程类函数')
        self.func()
        print('结束进程类函数')

if __name__ == '__main__':
    p = MyProcess()
    p.start()
```

创建线程类

```
from threading import Thread
import time

class MyThread(Thread):

    def __init__(self):
        super().__init__()

    def run(self) -> None:
        print('开始线程类函数')
        time.sleep(2)
        print('结束线程类函数')

if __name__ == '__main__':
    
    t = MyThread()
    t.start()
```



# 进程池（线程池）

### 锁

死锁：两个或者两个以上的线程或者进程在执行的过程中 因资源竞争出现的情况。

递归锁：可以多次加锁

```python
from threading import Thread ,  RLock 
import time

class MyThread(Thread):

    def __init__(self):
        super().__init__()

    def func(self):
        ll.acquire()
        print('拿到ll的锁')
        tl.acquire()
        print('拿到tl的锁')
        tl.release()
        ll.release()

    def run(self) -> None:
        tl.acquire()
        ll.acquire()
        print('开始线程类函数')
        time.sleep(2)
        self.func()
        print('结束线程类函数')
        tl.release()
        ll.release()

if __name__ == '__main__':
    # 递归锁这里面会有一个变量 ， 这个变量就是记录了这个锁被锁了几次
    ll = tl = RLock()
    t = MyThread()
    t.start()
```

### 定时器

```
from threading import  Timer
import time
# 让线程任务在什么时候进程执行

def func():
    print('线程执行之后的时间')
    print(time.strftime("%Y-%m-%d  %H:%M:%S"))


if __name__ == '__main__':
    print(time.strftime("%Y-%m-%d  %H:%M:%S"))
    # Timer(等待时间 ， 执行的任务)
    t = Timer(2 , func)
    t.start()
```

### Event(了解)

Event本质就是一个标志 ， 有True和False进行表示 ， False表示为阻塞状态 ， 初始化Event对象默认为False

```
from  threading import  Thread , Event
import time
import random


def func():
    # 红绿灯
    while True:
        e.clear()   # 恢复event的状态值为False ， 即将值设置为False
        print('红灯亮起')
        time.sleep(5)
        e.set()     # 设置event的值为True ， 激活线程任务 ， 等待操作系统进行调度执行
        print('绿灯亮起')
        time.sleep(4)

def person(name):
    while True:
        # 判断event状态值
        if e.is_set():
            print(f'{name}行人正在通行')
            break
        else:
            print(f'{name}行人正在等待')
            e.wait()


if __name__ == '__main__':
    e = Event() # 默认是False
    Thread(target=func).start()
    num = 0
    while True:
        num += 1
        # 创建随机时间 ， 在随机时间之后产生一个路人过红绿灯
        time.sleep(random.randint(0,3))
        t = Thread(target=person , args=(f'路人{num}',))
        t.start()
```

### 进程通信

Queue本身就是一个消息队列程序

multiprocessing提供了Queue可以实现多进程之间的数据传递

```
from  multiprocessing import Queue
import queue

# 要初始化Queue对象 ， 设置接收put消息的条数
q = Queue(5)
q.put('put1号')
q.put('put2号')
q.put('put3号')
q.put('put4号')
q.put('put5号')


#  q.full()判断消息队列是否满了
# print(q.full())

try :
    q.put_nowait('6号')
except queue.Full:
    print('消息队列已经满员')

# 返回当前消息队列内所包含的消息数量
print(q.qsize())

# 判断当前队列是否为空 ， 返回True ， False
print(q.empty())

print(q.get())

print(q.get_nowait())
```

```
from  multiprocessing import  Process , Queue
import time

def write(q):
    # 将数据写入到queue消息队列中
    ls = ['鲁班','李白','武则天','孙尚香']
    for i in ls:
        q.put(i)
        print('queue获取到值',i)
        time.sleep(2)

def read(q):
    # 从消息队列中获取数据
    while True:
        if not q.empty():
            value = q.get(True)
            print('从消息队列中获取到值',value)
            time.sleep(3)
        else:
            break



if __name__ == '__main__':
    q = Queue()
    w = Process(target=write , args=(q,))
    r = Process(target=read , args=(q,))
    # 将消息全部完整的写入到消息队列中 ，才继续下一个进程
    w.start()
    w.join()
    r.start()
    r.join()
    print('数据写入读取完毕')
```

### 进程池（线程池）

进程池的概念：定义一个水池 ， 不断的往里面放上固定数量的进程任务 ， 有需求就在池中的进程进行处理 ， 等待处理完毕，且进程不关闭，而是将进程重新放回进程池中等待新的任务需求进行调度。可以节省开闭进程的时间

```
from  concurrent.futures import ProcessPoolExecutor
from  concurrent.futures import ThreadPoolExecutor
import time

# 设置进程池的进程数量 , 实例化进程池
p = ProcessPoolExecutor(5)


def func(n):
    print(n)
    time.sleep(2)


if __name__ == '__main__':
    for i in range(20):
        p.submit(func , i)
```

```
# submit(func , i)该返回是有返回值的 ， 返回的是Future对象 ， 这个对象有result方法
# 可以通过这个方法获取返回提交的任务的返回值结果
from  concurrent.futures import ProcessPoolExecutor
from  concurrent.futures import ThreadPoolExecutor
import time

# 设置进程池的进程数量 , 实例化进程池
p = ProcessPoolExecutor(5)


def func(n):
    print(n)
    time.sleep(2)
    return n * 2


if __name__ == '__main__':
    for i in range(20):
        res = p.submit(func, i)
        print('返回值是',res.result())
```

```
# shutdown()
from  concurrent.futures import ProcessPoolExecutor
from  concurrent.futures import ThreadPoolExecutor
import time

# 设置进程池的进程数量 , 实例化进程池
p = ProcessPoolExecutor(5)


def func(n):
    print(n)
    time.sleep(2)
    return n * 2


if __name__ == '__main__':
    l = []
    for i in range(20):
        res = p.submit(func, i)
        l.append(res)
    # 等待进程池中的所有进程任务全部执行完毕
    p.shutdown()
    for i in l:
        print('返回值是',i.result())
```

```
# add_done_callback(func_A) 回调机制
from  concurrent.futures import ProcessPoolExecutor
from  concurrent.futures import ThreadPoolExecutor
import time

# 设置进程池的进程数量 , 实例化进程池
p = ProcessPoolExecutor(5)


def func(n):
    print(n)
    time.sleep(2)
    return n * 2

def func_A(fun):
    print(f'获取返回值结果{fun.result()}')



if __name__ == '__main__':
    # l = []
    for i in range(5):
        res = p.submit(func, i)
        time.sleep(1)
        # 回调机制
        # 回调机制不需要对任务进行参数传递 ， 会自动的传入参数
        res.add_done_callback(func_A)
```

```
# 下载模块
pip install greenlet
pip install gevent
```



